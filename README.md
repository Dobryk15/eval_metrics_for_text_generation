# eval_metrics_for_text_generation
This repo is devoted to the comparison of evaluation metrics for NLP text generation task
